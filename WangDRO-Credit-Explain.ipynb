{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,json\n",
    "from glob import glob\n",
    "\n",
    "os.chdir('/home/avijit/projects/Awareness_vs_Unawareness')\n",
    "sys.path.insert(0,\"/home/avijit/projects/Awareness_vs_Unawareness/robustfairnesscode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/avijit/projects/Awareness_vs_Unawareness/robustfairnesscode/dro_training.py:20: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from robustfairnesscode import data, losses, optimization, model, utils, dro_training, softweights_training\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import shap\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writejson(path,arr,name):\n",
    "    try:\n",
    "        os.mkdir(path+'preds/')\n",
    "    except:\n",
    "        pass\n",
    "    f = open(path+'preds/'+name,'w')\n",
    "    json.dump(arr,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {0:'data/datasets/credit_tw/',\n",
    "         0.2:'data/datasets/credit_tw/synthetic/gender_flip_labels0.2_version0/',\n",
    "         0.4:'data/datasets/credit_tw/synthetic/gender_flip_labels0.4_version0/',\n",
    "         0.6:'data/datasets/credit_tw/synthetic/gender_flip_labels0.6_version0/',\n",
    "         0.8:'data/datasets/credit_tw/synthetic/gender_flip_labels0.8_version0/'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dothings(model,name):\n",
    "    session = tf.Session()\n",
    "    session.run((tf.global_variables_initializer(),tf.local_variables_initializer()))\n",
    "    \n",
    "    def f(test_df):\n",
    "        val = session.run(model.predictions_tensor,feed_dict=model.feed_dict_helper(test_df))\n",
    "        vall = [float(v[0]) for v in val]\n",
    "        val_m = [0 if i < 0 else 1 for i in vall]\n",
    "        return val_m\n",
    "    \n",
    "    explainer = shap.Explainer(f, test_df)\n",
    "    shap_values = explainer(test_df.sample(n=500))\n",
    "    \n",
    "    clist = list(FEATURE_NAMES)\n",
    "    features = {}\n",
    "    for i in range(len(clist)):\n",
    "        fname = clist[i]\n",
    "        item = fname.split('_')[0]\n",
    "        if item not in features:\n",
    "            features[item]=[]\n",
    "        features[item].append(i)\n",
    "    newshap = {}\n",
    "    for k in features:\n",
    "        nshap = []\n",
    "        for x in shap_values.values:\n",
    "            val = 0\n",
    "            for i in features[k]:\n",
    "                val+= x[i]\n",
    "            nshap.append(val)\n",
    "        newshap[k] = nshap\n",
    "    new_shap_values = list(zip(*newshap.values()))\n",
    "    shap_values.values = np.array(new_shap_values)\n",
    "    shap_values.feature_names = list(features.keys())\n",
    "    \n",
    "    f = open('SavedShap/'+name+'.pkl','wb')\n",
    "    pickle.dump(shap_values,f)\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    shap.plots.bar(shap_values,max_display=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SEX_Female', 'SEX_Male', 'LIMITBAL', 'EDUCATION', 'MARRIAGE', 'AGE',\n",
      "       'PAY0', 'PAY2', 'PAY3', 'PAY4', 'PAY5', 'PAY6', 'BILLAMT1', 'BILLAMT2',\n",
      "       'BILLAMT3', 'BILLAMT4', 'BILLAMT5', 'BILLAMT6', 'PAYAMT1', 'PAYAMT2',\n",
      "       'PAYAMT3', 'PAYAMT4', 'PAYAMT5', 'PAYAMT6', 'DEFAULT_PAY'],\n",
      "      dtype='object')\n",
      "Split 0 of 10\n",
      "Time since start: 0.005113124847412109\n",
      "Starting optimizing learning rate theta: 0.100, learning rate lambda: 1.000, learning rate W: 0.100\n",
      "WARNING:tensorflow:From /home/avijit/projects/Awareness_vs_Unawareness/robustfairnesscode/model.py:50: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/avijit/anaconda3/envs/oscar/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f062f483190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f062f483190>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f062f483190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f062f483190>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From /home/avijit/projects/Awareness_vs_Unawareness/robustfairnesscode/softweights_training.py:334: The name tf.losses.hinge_loss is deprecated. Please use tf.compat.v1.losses.hinge_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/avijit/anaconda3/envs/oscar/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/avijit/projects/Awareness_vs_Unawareness/robustfairnesscode/softweights_training.py:376: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/avijit/projects/Awareness_vs_Unawareness/robustfairnesscode/softweights_training.py:394: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/avijit/projects/Awareness_vs_Unawareness/robustfairnesscode/softweights_training.py:404: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/avijit/projects/Awareness_vs_Unawareness/robustfairnesscode/softweights_training.py:405: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/avijit/projects/Awareness_vs_Unawareness/robustfairnesscode/softweights_training.py:406: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8fc05c52cc6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     valmain2,best_learning_rate_theta2,best_learning_rate_lambda2,best_learning_rate_W2 = softweights_training.get_results_for_learning_rates(train_df, test_df, FEATURE_NAMES, \n\u001b[0;32m---> 55\u001b[0;31m                                                                        PROTECTED_COLUMNS, PROXY_COLUMNS, LABEL_COLUMN, num_loops = 1, constraint='tpr_and_fpr')\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     swmodel = softweights_training.get_model_for_learning_rates(train_df, test_df,  FEATURE_NAMES, PROTECTED_COLUMNS, PROXY_COLUMNS, LABEL_COLUMN, learning_rate_theta = best_learning_rate_theta2, \n",
      "\u001b[0;32m~/projects/Awareness_vs_Unawareness/robustfairnesscode/softweights_training.py\u001b[0m in \u001b[0;36mget_results_for_learning_rates\u001b[0;34m(input_df, test_df, feature_names, protected_columns, proxy_columns, label_column, constraint, learning_rates_theta, learning_rates_lambda, learning_rates_W, num_runs, minibatch_size, num_iterations_per_loop, num_loops, constraints_slack, num_avg_iters, optimize_robust_constraints, rank_objectives, max_constraints, num_iterations_W, max_diff, best_index_nburn, seed_start)\u001b[0m\n\u001b[1;32m   1007\u001b[0m                           \u001b[0mnum_iterations_W\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iterations_W\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m                           \u001b[0mmax_diff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_diff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m                           constraint=constraint)\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                     \u001b[0;31m# Get best iterate using training set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Awareness_vs_Unawareness/robustfairnesscode/softweights_training.py\u001b[0m in \u001b[0;36mtraining_helper\u001b[0;34m(sw_model, train_df, val_df, test_df, protected_columns, proxy_columns, label_column, minibatch_size, num_iterations_per_loop, num_loops, optimize_robust_constraints, num_iterations_W, max_diff, constraint)\u001b[0m\n\u001b[1;32m    786\u001b[0m     for objective, constraints, train_predictions, lambda_variables, W_variable, val_predictions, test_predictions in training_generator(\n\u001b[1;32m    787\u001b[0m       \u001b[0msw_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations_per_loop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m       num_loops, num_iterations_W=num_iterations_W):\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0mtrain_hinge_objective_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mtrain_hinge_constraints_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Awareness_vs_Unawareness/robustfairnesscode/softweights_training.py\u001b[0m in \u001b[0;36mtraining_generator\u001b[0;34m(sw_model, train_df, val_df, test_df, minibatch_size, num_iterations_per_loop, num_loops, num_iterations_W)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 session.run(\n\u001b[1;32m    426\u001b[0m                       \u001b[0msw_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op_W\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                       feed_dict=sw_model.feed_dict_helper(minibatch_df))\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0;31m# Descent step on theta.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             session.run(\n",
      "\u001b[0;32m~/anaconda3/envs/oscar/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/oscar/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/oscar/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/oscar/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/oscar/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/oscar/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for frac in paths:\n",
    "    path = paths[frac]\n",
    "    \n",
    "    train_df = pd.read_csv(path+'train.csv',header=None)\n",
    "\n",
    "    train_df.columns = ['LIMITBAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY0', 'PAY2',\n",
    "           'PAY3', 'PAY4', 'PAY5', 'PAY6', 'BILLAMT1', 'BILLAMT2',\n",
    "           'BILLAMT3', 'BILLAMT4', 'BILLAMT5', 'BILLAMT6', 'PAYAMT1',\n",
    "           'PAYAMT2', 'PAYAMT3', 'PAYAMT4', 'PAYAMT5', 'PAYAMT6',\n",
    "           'DEFAULT_PAY']\n",
    "\n",
    "    train_df = train_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "    test_df = pd.read_csv(path+'test.csv',header=None)\n",
    "\n",
    "    test_df.columns = ['LIMITBAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY0', 'PAY2',\n",
    "           'PAY3', 'PAY4', 'PAY5', 'PAY6', 'BILLAMT1', 'BILLAMT2',\n",
    "           'BILLAMT3', 'BILLAMT4', 'BILLAMT5', 'BILLAMT6', 'PAYAMT1',\n",
    "           'PAYAMT2', 'PAYAMT3', 'PAYAMT4', 'PAYAMT5', 'PAYAMT6',\n",
    "           'DEFAULT_PAY']\n",
    "\n",
    "    X_train = train_df.drop(['DEFAULT_PAY'],axis=1)\n",
    "    X_test = test_df.drop(['DEFAULT_PAY'],axis=1)\n",
    "\n",
    "    Y_train = pd.Series(train_df['DEFAULT_PAY'])\n",
    "    Y_test = pd.Series(test_df['DEFAULT_PAY'])\n",
    "\n",
    "    Y_train = pd.Series(Y_train.factorize(sort=True)[0], index=Y_train.index)\n",
    "    Y_test = pd.Series(Y_test.factorize(sort=True)[0], index=Y_test.index)\n",
    "\n",
    "    X_merged = pd.concat([X_train,X_test])\n",
    "\n",
    "    ohe = make_column_transformer(\n",
    "        (OneHotEncoder(sparse=False), X_merged.dtypes == 'object'),\n",
    "        remainder='passthrough', verbose_feature_names_out=False)\n",
    "\n",
    "    X_merged_temp  = pd.DataFrame(ohe.fit_transform(X_merged), columns=ohe.get_feature_names_out(), index=X_merged.index)\n",
    "\n",
    "    train_df  = pd.DataFrame(ohe.transform(X_train), columns=ohe.get_feature_names_out(), index=X_train.index)\n",
    "    test_df = pd.DataFrame(ohe.transform(X_test), columns=ohe.get_feature_names_out(), index=X_test.index)\n",
    "\n",
    "    train_df['DEFAULT_PAY'] = Y_train\n",
    "    test_df['DEFAULT_PAY'] = Y_test\n",
    "\n",
    "    print(train_df.columns)\n",
    "\n",
    "    LABEL_COLUMN = \"DEFAULT_PAY\"\n",
    "    FEATURE_NAMES = list(train_df.columns)\n",
    "    FEATURE_NAMES.remove(LABEL_COLUMN)\n",
    "    PROTECTED_COLUMNS = ['SEX_Female','SEX_Male']\n",
    "\n",
    "    PROXY_COLUMNS = PROTECTED_COLUMNS  \n",
    "    \n",
    "    valmain2,best_learning_rate_theta2,best_learning_rate_lambda2,best_learning_rate_W2 = softweights_training.get_results_for_learning_rates(train_df, test_df, FEATURE_NAMES, \n",
    "                                                                       PROTECTED_COLUMNS, PROXY_COLUMNS, LABEL_COLUMN, num_loops = 1, constraint='tpr_and_fpr')\n",
    "\n",
    "    swmodel = softweights_training.get_model_for_learning_rates(train_df, test_df,  FEATURE_NAMES, PROTECTED_COLUMNS, PROXY_COLUMNS, LABEL_COLUMN, learning_rate_theta = best_learning_rate_theta2, \n",
    "                                                        learning_rate_lambda = best_learning_rate_lambda2, learning_rate_W = best_learning_rate_W2, num_loops = 1,constraint='tpr_and_fpr')\n",
    "\n",
    "\n",
    "    name = 'credit_tw_soft_'+str(frac)\n",
    "    \n",
    "    dothings(swmodel,name)\n",
    "\n",
    "\n",
    "    valmain,best_learning_rate_theta,best_learning_rate_lambda,best_learning_rate_p_list = dro_training.get_results_for_learning_rates(train_df, test_df, FEATURE_NAMES, \n",
    "                                                      PROTECTED_COLUMNS, PROXY_COLUMNS, LABEL_COLUMN, num_loops = 1,constraint='tpr_and_fpr')\n",
    "\n",
    "    model = dro_training.get_model_for_learning_rates(train_df, test_df,  FEATURE_NAMES, PROTECTED_COLUMNS, PROXY_COLUMNS, LABEL_COLUMN, learning_rate_theta = best_learning_rate_theta, \n",
    "                                                        learning_rate_lambda = best_learning_rate_lambda, learning_rate_p_list = best_learning_rate_p_list, num_loops = 1,constraint='tpr_and_fpr')\n",
    "\n",
    "    name = 'credit_tw_mdro_'+str(frac)\n",
    "    \n",
    "    dothings(model,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:oscar]",
   "language": "python",
   "name": "conda-env-oscar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
