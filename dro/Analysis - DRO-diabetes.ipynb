{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying Code from main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from robust_losses import RobustLoss\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from torch.utils.data import Dataset\n",
    "from glob import glob\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(MyDataset, self).__init__()\n",
    "        assert x.shape[0] == y.shape[0] # assuming shape[0] = dataset size\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Reg_model(torch.nn.Module):\n",
    "    def __init__(self,no_input_features):\n",
    "        super(Logistic_Reg_model,self).__init__()\n",
    "        self.layer1=torch.nn.Linear(no_input_features,64)\n",
    "        self.layer2=torch.nn.Linear(64,1)\n",
    "    def forward(self,x):\n",
    "        y_predicted=self.layer1(x)\n",
    "        y_predicted=torch.sigmoid(self.layer2(y_predicted))\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testaccuracy():\n",
    "    with torch.no_grad():\n",
    "        y_pred=model(x_test)\n",
    "        y_pred_class=y_pred.round()\n",
    "        accuracy=(y_pred_class.eq(y_test).sum())/float(y_test.shape[0])\n",
    "        return (accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel():\n",
    "    fname = \"DRO_model_diabetes.pth\"\n",
    "    torch.save(model.state_dict(), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/datasets/diabetes/'\n",
    "synthfols = glob(\"../data/datasets/diabetes/synthetic/*/\")\n",
    "paths = [path]\n",
    "paths.extend(synthfols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/datasets/diabetes/\n",
      "[1,    10] loss: 2.641\n",
      "[1,    20] loss: 1.249\n",
      "[1,    30] loss: 0.898\n",
      "[1,    40] loss: 0.793\n",
      "[1,    50] loss: 0.738\n",
      "accuracy: 0.541456937789917\n",
      "best: 0.0\n",
      "[2,    10] loss: 0.708\n",
      "[2,    20] loss: 0.697\n",
      "[2,    30] loss: 0.696\n",
      "[2,    40] loss: 0.691\n",
      "[2,    50] loss: 0.686\n",
      "accuracy: 0.609619677066803\n",
      "best: 0.541456937789917\n",
      "[3,    10] loss: 0.685\n",
      "[3,    20] loss: 0.684\n",
      "[3,    30] loss: 0.683\n",
      "[3,    40] loss: 0.683\n",
      "[3,    50] loss: 0.685\n",
      "accuracy: 0.6165408492088318\n",
      "best: 0.609619677066803\n",
      "[4,    10] loss: 0.682\n",
      "[4,    20] loss: 0.682\n",
      "[4,    30] loss: 0.681\n",
      "[4,    40] loss: 0.683\n",
      "[4,    50] loss: 0.683\n",
      "accuracy: 0.61982661485672\n",
      "best: 0.6165408492088318\n",
      "[5,    10] loss: 0.682\n",
      "[5,    20] loss: 0.682\n",
      "[5,    30] loss: 0.681\n",
      "[5,    40] loss: 0.682\n",
      "[5,    50] loss: 0.683\n",
      "accuracy: 0.6224133372306824\n",
      "best: 0.61982661485672\n",
      "[6,    10] loss: 0.680\n",
      "[6,    20] loss: 0.682\n",
      "[6,    30] loss: 0.682\n",
      "[6,    40] loss: 0.679\n",
      "[6,    50] loss: 0.683\n",
      "accuracy: 0.6187779903411865\n",
      "best: 0.6224133372306824\n",
      "[7,    10] loss: 0.683\n",
      "[7,    20] loss: 0.680\n",
      "[7,    30] loss: 0.682\n",
      "[7,    40] loss: 0.680\n",
      "[7,    50] loss: 0.681\n",
      "accuracy: 0.6205257177352905\n",
      "best: 0.6224133372306824\n",
      "[8,    10] loss: 0.680\n",
      "[8,    20] loss: 0.682\n",
      "[8,    30] loss: 0.681\n",
      "[8,    40] loss: 0.680\n",
      "[8,    50] loss: 0.681\n",
      "accuracy: 0.6203858852386475\n",
      "best: 0.6224133372306824\n",
      "[9,    10] loss: 0.681\n",
      "[9,    20] loss: 0.680\n",
      "[9,    30] loss: 0.681\n",
      "[9,    40] loss: 0.682\n",
      "[9,    50] loss: 0.681\n",
      "accuracy: 0.6201761960983276\n",
      "best: 0.6224133372306824\n",
      "[10,    10] loss: 0.682\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_338616/2418937941.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0my_prediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_338616/3233206853.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    \n",
    "    print(path)\n",
    "    \n",
    "    if os.path.exists(path+'preds/OG_DRO_pred.pt') == False:\n",
    "\n",
    "        train_df = pd.read_csv(path+'train.csv',header=None)\n",
    "\n",
    "        train_df.columns = ['race', 'sex', 'age', 'admissiontypeid', 'dischargedispositionid',\n",
    "           'admissionsourceid', 'timeinhospital', 'numlabprocedures',\n",
    "            'numprocedures', 'nummedications', 'numberoutpatient',\n",
    "            'numberemergency', 'numberinpatient', 'diag1', 'diag2', 'diag3',\n",
    "            'numberdiagnoses', 'maxgluserum', 'A1Cresult', 'metformin',\n",
    "            'glimepiride', 'glipizide', 'glyburide', 'pioglitazone',\n",
    "            'rosiglitazone', 'insulin', 'change', 'diabetesMed', 'readmitted']\n",
    "\n",
    "    #     train_df.index = train_df['SEX']\n",
    "\n",
    "        train_df = train_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "        test_df = pd.read_csv(path+'test.csv',header=None)\n",
    "\n",
    "        test_df.columns = ['race', 'sex', 'age', 'admissiontypeid', 'dischargedispositionid',\n",
    "           'admissionsourceid', 'timeinhospital', 'numlabprocedures',\n",
    "           'numprocedures', 'nummedications', 'numberoutpatient',\n",
    "           'numberemergency', 'numberinpatient', 'diag1', 'diag2', 'diag3',\n",
    "           'numberdiagnoses', 'maxgluserum', 'A1Cresult', 'metformin',\n",
    "           'glimepiride', 'glipizide', 'glyburide', 'pioglitazone',\n",
    "           'rosiglitazone', 'insulin', 'change', 'diabetesMed', 'readmitted']\n",
    "\n",
    "    #     test_df = test_df.drop(['SEX'],axis=1)\n",
    "\n",
    "    #     test_df.index = test_df['SEX']\n",
    "\n",
    "        test_df = test_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "\n",
    "        x_train = train_df.drop(['readmitted','sex'],axis=1)\n",
    "        x_test = test_df.drop(['readmitted','sex'],axis=1)\n",
    "\n",
    "        x_merged = pd.concat([x_train,x_test])\n",
    "\n",
    "        ohe = make_column_transformer(\n",
    "            (OneHotEncoder(sparse=False), x_merged.dtypes == 'object'),\n",
    "            remainder='passthrough', verbose_feature_names_out=False)\n",
    "\n",
    "        x_merged_temp  = pd.DataFrame(ohe.fit_transform(x_merged), columns=ohe.get_feature_names_out(), index=x_merged.index)\n",
    "\n",
    "        x_train  = pd.DataFrame(ohe.transform(x_train), columns=ohe.get_feature_names_out(), index=x_train.index)\n",
    "        x_test = pd.DataFrame(ohe.transform(x_test), columns=ohe.get_feature_names_out(), index=x_test.index)\n",
    "\n",
    "        y_train = pd.Series(train_df['readmitted'])\n",
    "        y_test = pd.Series(test_df['readmitted'])\n",
    "\n",
    "        y_train = pd.Series(y_train.factorize(sort=True)[0], index=y_train.index)\n",
    "        y_test = pd.Series(y_test.factorize(sort=True)[0], index=y_test.index)\n",
    "\n",
    "        x_train=torch.from_numpy(x_train.to_numpy().astype(np.float32))\n",
    "        x_test=torch.from_numpy(x_test.to_numpy().astype(np.float32))\n",
    "        y_train=torch.from_numpy(y_train.to_numpy().astype(np.float32))\n",
    "        y_test=torch.from_numpy(y_test.to_numpy().astype(np.float32))\n",
    "\n",
    "        y_train=y_train.view(y_train.shape[0],1)\n",
    "        y_test=y_test.view(y_test.shape[0],1)\n",
    "\n",
    "        traindata = MyDataset(x_train, y_train)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(traindata, batch_size=1000, shuffle=True)\n",
    "\n",
    "        n_features = x_train.shape[1]\n",
    "        model=Logistic_Reg_model(n_features)\n",
    "\n",
    "        criterion=torch.nn.BCELoss(reduction='none')\n",
    "        robust_loss = RobustLoss(geometry='chi-square', size=1.0, reg=0.5)\n",
    "        optimizer=torch.optim.Adam(model.parameters())#,lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "        number_of_epochs=100\n",
    "        best_accuracy = 0.0\n",
    "\n",
    "        for epoch in range(number_of_epochs):\n",
    "            running_loss = 0.0\n",
    "            for i, (x_b, y_b) in enumerate(trainloader, 0):\n",
    "                optimizer.zero_grad()\n",
    "                y_prediction=model(x_b)\n",
    "                loss=robust_loss(criterion(y_prediction.squeeze(),y_b.squeeze()))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() \n",
    "                if (i)%10 == 9:\n",
    "                    print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 10))\n",
    "                    running_loss = 0.0\n",
    "            accuracy = testaccuracy()\n",
    "            print('accuracy:', accuracy)\n",
    "            print('best:', best_accuracy)\n",
    "            if accuracy > best_accuracy:\n",
    "                saveModel()\n",
    "                best_accuracy = accuracy\n",
    "\n",
    "        finalmodel = Logistic_Reg_model(n_features)\n",
    "        finalmodel.load_state_dict(torch.load('DRO_model_diabetes.pth'))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred=finalmodel(x_test)\n",
    "            y_pred_class=y_pred.round()\n",
    "            try:\n",
    "                os.mkdir(path+'preds/')\n",
    "            except:\n",
    "                pass\n",
    "            torch.save(y_pred_class,path+'preds/OG_DRO_pred.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
