{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying Code from main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from robust_losses import RobustLoss\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from torch.utils.data import Dataset\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(MyDataset, self).__init__()\n",
    "        assert x.shape[0] == y.shape[0] # assuming shape[0] = dataset size\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Reg_model(torch.nn.Module):\n",
    "    def __init__(self,no_input_features):\n",
    "        super(Logistic_Reg_model,self).__init__()\n",
    "        self.layer1=torch.nn.Linear(no_input_features,64)\n",
    "        self.layer2=torch.nn.Linear(64,1)\n",
    "    def forward(self,x):\n",
    "        y_predicted=self.layer1(x)\n",
    "        y_predicted=torch.sigmoid(self.layer2(y_predicted))\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testaccuracy():\n",
    "    with torch.no_grad():\n",
    "        y_pred=model(x_test)\n",
    "        y_pred_class=y_pred.round()\n",
    "        accuracy=(y_pred_class.eq(y_test).sum())/float(y_test.shape[0])\n",
    "        return (accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel():\n",
    "    fname = \"DRO_model.pth\"\n",
    "    torch.save(model.state_dict(), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/datasets/uci_adult/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthfols = glob(\"../data/datasets/uci_adult/synthetic/*/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [path]\n",
    "# paths.extend(synthfols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 76.222\n",
      "[1,    20] loss: 76.991\n",
      "[1,    30] loss: 76.486\n",
      "[1,    40] loss: 76.976\n",
      "[1,    50] loss: 76.505\n",
      "[1,    60] loss: 75.627\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.0\n",
      "[2,    10] loss: 76.294\n",
      "[2,    20] loss: 76.152\n",
      "[2,    30] loss: 76.480\n",
      "[2,    40] loss: 76.816\n",
      "[2,    50] loss: 76.273\n",
      "[2,    60] loss: 77.045\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[3,    10] loss: 76.845\n",
      "[3,    20] loss: 76.558\n",
      "[3,    30] loss: 75.339\n",
      "[3,    40] loss: 76.883\n",
      "[3,    50] loss: 77.215\n",
      "[3,    60] loss: 76.377\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[4,    10] loss: 76.357\n",
      "[4,    20] loss: 76.435\n",
      "[4,    30] loss: 77.050\n",
      "[4,    40] loss: 76.780\n",
      "[4,    50] loss: 76.934\n",
      "[4,    60] loss: 76.183\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[5,    10] loss: 76.443\n",
      "[5,    20] loss: 76.635\n",
      "[5,    30] loss: 76.140\n",
      "[5,    40] loss: 76.250\n",
      "[5,    50] loss: 76.307\n",
      "[5,    60] loss: 77.332\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[6,    10] loss: 75.644\n",
      "[6,    20] loss: 76.975\n",
      "[6,    30] loss: 76.352\n",
      "[6,    40] loss: 76.655\n",
      "[6,    50] loss: 76.583\n",
      "[6,    60] loss: 76.945\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[7,    10] loss: 76.851\n",
      "[7,    20] loss: 76.435\n",
      "[7,    30] loss: 76.103\n",
      "[7,    40] loss: 76.240\n",
      "[7,    50] loss: 76.453\n",
      "[7,    60] loss: 76.979\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[8,    10] loss: 77.012\n",
      "[8,    20] loss: 75.366\n",
      "[8,    30] loss: 77.164\n",
      "[8,    40] loss: 76.440\n",
      "[8,    50] loss: 76.106\n",
      "[8,    60] loss: 76.620\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[9,    10] loss: 76.654\n",
      "[9,    20] loss: 77.559\n",
      "[9,    30] loss: 76.206\n",
      "[9,    40] loss: 75.077\n",
      "[9,    50] loss: 76.892\n",
      "[9,    60] loss: 76.733\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[10,    10] loss: 76.554\n",
      "[10,    20] loss: 76.943\n",
      "[10,    30] loss: 76.400\n",
      "[10,    40] loss: 76.311\n",
      "[10,    50] loss: 75.935\n",
      "[10,    60] loss: 77.056\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[11,    10] loss: 76.041\n",
      "[11,    20] loss: 75.911\n",
      "[11,    30] loss: 76.658\n",
      "[11,    40] loss: 77.307\n",
      "[11,    50] loss: 76.837\n",
      "[11,    60] loss: 75.651\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[12,    10] loss: 75.923\n",
      "[12,    20] loss: 76.734\n",
      "[12,    30] loss: 76.300\n",
      "[12,    40] loss: 76.231\n",
      "[12,    50] loss: 76.724\n",
      "[12,    60] loss: 76.891\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[13,    10] loss: 76.981\n",
      "[13,    20] loss: 76.452\n",
      "[13,    30] loss: 77.017\n",
      "[13,    40] loss: 75.625\n",
      "[13,    50] loss: 76.654\n",
      "[13,    60] loss: 76.325\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[14,    10] loss: 76.337\n",
      "[14,    20] loss: 76.594\n",
      "[14,    30] loss: 76.778\n",
      "[14,    40] loss: 75.793\n",
      "[14,    50] loss: 76.758\n",
      "[14,    60] loss: 76.694\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[15,    10] loss: 76.961\n",
      "[15,    20] loss: 75.151\n",
      "[15,    30] loss: 77.055\n",
      "[15,    40] loss: 75.737\n",
      "[15,    50] loss: 76.439\n",
      "[15,    60] loss: 77.343\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[16,    10] loss: 75.665\n",
      "[16,    20] loss: 77.080\n",
      "[16,    30] loss: 76.177\n",
      "[16,    40] loss: 76.577\n",
      "[16,    50] loss: 76.458\n",
      "[16,    60] loss: 77.085\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[17,    10] loss: 77.506\n",
      "[17,    20] loss: 75.685\n",
      "[17,    30] loss: 76.978\n",
      "[17,    40] loss: 76.862\n",
      "[17,    50] loss: 75.369\n",
      "[17,    60] loss: 76.280\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[18,    10] loss: 76.701\n",
      "[18,    20] loss: 77.649\n",
      "[18,    30] loss: 76.260\n",
      "[18,    40] loss: 75.806\n",
      "[18,    50] loss: 76.439\n",
      "[18,    60] loss: 76.297\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[19,    10] loss: 77.309\n",
      "[19,    20] loss: 77.152\n",
      "[19,    30] loss: 75.702\n",
      "[19,    40] loss: 75.440\n",
      "[19,    50] loss: 76.965\n",
      "[19,    60] loss: 76.595\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[20,    10] loss: 76.244\n",
      "[20,    20] loss: 76.774\n",
      "[20,    30] loss: 76.278\n",
      "[20,    40] loss: 76.319\n",
      "[20,    50] loss: 76.687\n",
      "[20,    60] loss: 76.438\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[21,    10] loss: 76.415\n",
      "[21,    20] loss: 76.089\n",
      "[21,    30] loss: 76.888\n",
      "[21,    40] loss: 76.512\n",
      "[21,    50] loss: 75.573\n",
      "[21,    60] loss: 77.305\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[22,    10] loss: 76.450\n",
      "[22,    20] loss: 77.128\n",
      "[22,    30] loss: 76.925\n",
      "[22,    40] loss: 75.696\n",
      "[22,    50] loss: 76.440\n",
      "[22,    60] loss: 76.503\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[23,    10] loss: 77.315\n",
      "[23,    20] loss: 76.394\n",
      "[23,    30] loss: 77.317\n",
      "[23,    40] loss: 76.090\n",
      "[23,    50] loss: 76.379\n",
      "[23,    60] loss: 76.471\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[24,    10] loss: 76.748\n",
      "[24,    20] loss: 75.940\n",
      "[24,    30] loss: 76.438\n",
      "[24,    40] loss: 76.320\n",
      "[24,    50] loss: 77.602\n",
      "[24,    60] loss: 75.725\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[25,    10] loss: 76.533\n",
      "[25,    20] loss: 76.261\n",
      "[25,    30] loss: 75.704\n",
      "[25,    40] loss: 76.355\n",
      "[25,    50] loss: 77.428\n",
      "[25,    60] loss: 77.040\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[26,    10] loss: 76.736\n",
      "[26,    20] loss: 76.043\n",
      "[26,    30] loss: 77.414\n",
      "[26,    40] loss: 76.753\n",
      "[26,    50] loss: 76.640\n",
      "[26,    60] loss: 75.781\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[27,    10] loss: 76.360\n",
      "[27,    20] loss: 77.005\n",
      "[27,    30] loss: 76.674\n",
      "[27,    40] loss: 76.011\n",
      "[27,    50] loss: 76.635\n",
      "[27,    60] loss: 75.796\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[28,    10] loss: 75.326\n",
      "[28,    20] loss: 76.737\n",
      "[28,    30] loss: 77.060\n",
      "[28,    40] loss: 76.502\n",
      "[28,    50] loss: 76.503\n",
      "[28,    60] loss: 76.795\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[29,    10] loss: 76.683\n",
      "[29,    20] loss: 76.770\n",
      "[29,    30] loss: 77.148\n",
      "[29,    40] loss: 75.934\n",
      "[29,    50] loss: 76.352\n",
      "[29,    60] loss: 76.047\n",
      "accuracy: 0.22971561551094055\n",
      "best: 0.22971561551094055\n",
      "[30,    10] loss: 75.840\n",
      "[30,    20] loss: 75.923\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1937133/514178723.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0my_prediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0melem_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0melem_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for p in paths:\n",
    "    \n",
    "#     if os.path.exists(path+'preds/DRO_pred.pt') == False:\n",
    "\n",
    "    train_df = pd.read_csv(path+'train.csv',header=None)\n",
    "\n",
    "    train_df.columns = ['age', 'workclass', 'fnlwgt','education', 'education-num', 'marital-status',\n",
    "           'occupation', 'relationship', 'race', 'sex', 'capital-gain',\n",
    "           'capital-loss', 'hours-per-week', 'native-country','income']\n",
    "\n",
    "    train_df.index = train_df['sex']\n",
    "\n",
    "    train_df = train_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "\n",
    "    test_df = pd.read_csv(path+'test.csv',header=None)\n",
    "\n",
    "    test_df.columns = ['age', 'workclass', 'fnlwgt','education', 'education-num', 'marital-status',\n",
    "           'occupation', 'relationship', 'race', 'sex', 'capital-gain',\n",
    "           'capital-loss', 'hours-per-week', 'native-country','income']\n",
    "\n",
    "    test_df.index = test_df['sex']\n",
    "\n",
    "    x_train = train_df.drop(['income'],axis=1)\n",
    "    x_test = test_df.drop(['income'],axis=1)\n",
    "    \n",
    "    x_merged = pd.concat([x_train,x_test])\n",
    "\n",
    "    ohe = make_column_transformer(\n",
    "        (OneHotEncoder(sparse=False), x_merged.dtypes == 'object'),\n",
    "        remainder='passthrough', verbose_feature_names_out=False)\n",
    "\n",
    "    x_merged_temp  = pd.DataFrame(ohe.fit_transform(x_merged), columns=ohe.get_feature_names_out(), index=x_merged.index)\n",
    "\n",
    "    x_train  = pd.DataFrame(ohe.transform(x_train), columns=ohe.get_feature_names_out(), index=x_train.index)\n",
    "    x_test = pd.DataFrame(ohe.transform(x_test), columns=ohe.get_feature_names_out(), index=x_test.index)\n",
    "\n",
    "\n",
    "    y_train = pd.Series(train_df['income'])\n",
    "    y_test = pd.Series(test_df['income'])\n",
    "\n",
    "    y_train = pd.Series(y_train.factorize(sort=True)[0], index=y_train.index)\n",
    "    y_test = pd.Series(y_test.factorize(sort=True)[0], index=y_test.index)\n",
    "\n",
    "    x_train=torch.from_numpy(x_train.to_numpy().astype(np.float32))\n",
    "    x_test=torch.from_numpy(x_test.to_numpy().astype(np.float32))\n",
    "    y_train=torch.from_numpy(y_train.to_numpy().astype(np.float32))\n",
    "    y_test=torch.from_numpy(y_test.to_numpy().astype(np.float32))\n",
    "\n",
    "    y_train=y_train.view(y_train.shape[0],1)\n",
    "    y_test=y_test.view(y_test.shape[0],1)\n",
    "\n",
    "    traindata = MyDataset(x_train, y_train)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(traindata, batch_size=1000, shuffle=True)\n",
    "\n",
    "    n_features = x_train.shape[1]\n",
    "    model=Logistic_Reg_model(n_features)\n",
    "\n",
    "    criterion=torch.nn.BCELoss(reduction='none')\n",
    "    robust_loss = RobustLoss(geometry='chi-square', size=1.0, reg=0.5)\n",
    "    optimizer=torch.optim.Adam(model.parameters(),lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "    number_of_epochs=100\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(number_of_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (x_b, y_b) in enumerate(trainloader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            y_prediction=model(x_b)\n",
    "            loss=robust_loss(criterion(y_prediction.squeeze(),y_b.squeeze()))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() \n",
    "            if (i)%10 == 9:\n",
    "                print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 10))\n",
    "                running_loss = 0.0\n",
    "        accuracy = testaccuracy()\n",
    "        print('accuracy:', accuracy)\n",
    "        print('best:', best_accuracy)\n",
    "        if accuracy > best_accuracy:\n",
    "            saveModel()\n",
    "            best_accuracy = accuracy\n",
    "\n",
    "    finalmodel = Logistic_Reg_model(n_features)\n",
    "    finalmodel.load_state_dict(torch.load('DRO_model.pth'))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred=finalmodel(x_test)\n",
    "        y_pred_class=y_pred.round()\n",
    "        try:\n",
    "            os.mkdir(path+'preds/')\n",
    "        except:\n",
    "            pass\n",
    "        torch.save(y_pred_class,path+'preds/DRO_pred.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
