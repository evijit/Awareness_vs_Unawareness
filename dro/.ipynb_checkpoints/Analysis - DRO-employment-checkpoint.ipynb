{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying Code from main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from robust_losses import RobustLoss\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from torch.utils.data import Dataset\n",
    "from glob import glob\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(MyDataset, self).__init__()\n",
    "        assert x.shape[0] == y.shape[0] # assuming shape[0] = dataset size\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Reg_model(torch.nn.Module):\n",
    "    def __init__(self,no_input_features):\n",
    "        super(Logistic_Reg_model,self).__init__()\n",
    "        self.layer1=torch.nn.Linear(no_input_features,64)\n",
    "        self.layer2=torch.nn.Linear(64,1)\n",
    "    def forward(self,x):\n",
    "        y_predicted=self.layer1(x)\n",
    "        y_predicted=torch.sigmoid(self.layer2(y_predicted))\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testaccuracy():\n",
    "    with torch.no_grad():\n",
    "        y_pred=model(x_test)\n",
    "        y_pred_class=y_pred.round()\n",
    "        accuracy=(y_pred_class.eq(y_test).sum())/float(y_test.shape[0])\n",
    "        return (accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel():\n",
    "    fname = \"DRO_model.pth\"\n",
    "    torch.save(model.state_dict(), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/datasets/publiccov_tx/'\n",
    "synthfols = glob(\"../data/datasets/publiccov_tx/synthetic/*/\")\n",
    "paths = [path]\n",
    "paths.extend(synthfols)\n",
    "\n",
    "path = '../data/datasets/publiccov_ny/'\n",
    "synthfols = glob(\"../data/datasets/publiccov_ny/synthetic/*/\")\n",
    "paths.append(path)\n",
    "paths.extend(synthfols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 88.680\n",
      "[1,    20] loss: 99.641\n",
      "[1,    30] loss: 99.632\n",
      "[1,    40] loss: 99.628\n",
      "[1,    50] loss: 99.646\n",
      "accuracy: 0.4088823199272156\n",
      "best: 0.0\n",
      "[2,    10] loss: 99.645\n",
      "[2,    20] loss: 99.641\n",
      "[2,    30] loss: 99.641\n",
      "[2,    40] loss: 99.640\n",
      "[2,    50] loss: 99.643\n",
      "accuracy: 0.4088823199272156\n",
      "best: 0.4088823199272156\n",
      "[3,    10] loss: 99.639\n",
      "[3,    20] loss: 99.648\n",
      "[3,    30] loss: 99.643\n",
      "[3,    40] loss: 99.646\n",
      "[3,    50] loss: 99.635\n",
      "accuracy: 0.4088823199272156\n",
      "best: 0.4088823199272156\n",
      "[4,    10] loss: 99.647\n",
      "[4,    20] loss: 99.638\n",
      "[4,    30] loss: 99.630\n",
      "[4,    40] loss: 99.643\n",
      "[4,    50] loss: 99.647\n",
      "accuracy: 0.4088823199272156\n",
      "best: 0.4088823199272156\n",
      "[5,    10] loss: 99.634\n",
      "[5,    20] loss: 99.650\n",
      "[5,    30] loss: 99.636\n",
      "[5,    40] loss: 99.647\n",
      "[5,    50] loss: 99.641\n",
      "accuracy: 0.4088823199272156\n",
      "best: 0.4088823199272156\n",
      "[6,    10] loss: 99.642\n",
      "[6,    20] loss: 99.648\n",
      "[6,    30] loss: 99.648\n",
      "[6,    40] loss: 99.635\n",
      "[6,    50] loss: 99.641\n",
      "accuracy: 0.4088823199272156\n",
      "best: 0.4088823199272156\n",
      "[7,    10] loss: 99.641\n",
      "[7,    20] loss: 99.646\n",
      "[7,    30] loss: 99.631\n",
      "[7,    40] loss: 99.647\n",
      "[7,    50] loss: 99.642\n",
      "accuracy: 0.4088823199272156\n",
      "best: 0.4088823199272156\n"
     ]
    }
   ],
   "source": [
    "for p in paths:\n",
    "    \n",
    "#     if os.path.exists(path+'preds/DRO_pred.pt') == False:\n",
    "\n",
    "    train_df = pd.read_csv(path+'train.csv',header=None)\n",
    "\n",
    "    train_df.columns = ['AGEP', 'SCHL', 'MAR', 'SEX', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC',\n",
    "       'NATIVITY', 'DEAR', 'DEYE', 'DREM', 'PINCP', 'ESR', 'FER', 'RAC1P',\n",
    "       'PUBCOV']\n",
    "\n",
    "\n",
    "    train_df.index = train_df['SEX']\n",
    "\n",
    "    train_df = train_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "    test_df = pd.read_csv(path+'test.csv',header=None)\n",
    "\n",
    "    test_df.columns = ['AGEP', 'SCHL', 'MAR', 'SEX', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC',\n",
    "       'NATIVITY', 'DEAR', 'DEYE', 'DREM', 'PINCP', 'ESR', 'FER', 'RAC1P',\n",
    "       'PUBCOV']\n",
    "\n",
    "\n",
    "    test_df.index = test_df['SEX']\n",
    "\n",
    "    test_df = test_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "\n",
    "    x_train = train_df.drop(['PUBCOV'],axis=1)\n",
    "    x_test = test_df.drop(['PUBCOV'],axis=1)\n",
    "\n",
    "    x_merged = pd.concat([x_train,x_test])\n",
    "\n",
    "    ohe = make_column_transformer(\n",
    "        (OneHotEncoder(sparse=False), x_merged.dtypes == 'object'),\n",
    "        remainder='passthrough', verbose_feature_names_out=False)\n",
    "\n",
    "    x_merged_temp  = pd.DataFrame(ohe.fit_transform(x_merged), columns=ohe.get_feature_names_out(), index=x_merged.index)\n",
    "\n",
    "    x_train  = pd.DataFrame(ohe.transform(x_train), columns=ohe.get_feature_names_out(), index=x_train.index)\n",
    "    x_test = pd.DataFrame(ohe.transform(x_test), columns=ohe.get_feature_names_out(), index=x_test.index)\n",
    "\n",
    "    y_train = pd.Series(train_df['PUBCOV'])\n",
    "    y_test = pd.Series(test_df['PUBCOV'])\n",
    "\n",
    "    y_train = pd.Series(y_train.factorize(sort=True)[0], index=y_train.index)\n",
    "    y_test = pd.Series(y_test.factorize(sort=True)[0], index=y_test.index)\n",
    "\n",
    "    x_train=torch.from_numpy(x_train.to_numpy().astype(np.float32))\n",
    "    x_test=torch.from_numpy(x_test.to_numpy().astype(np.float32))\n",
    "    y_train=torch.from_numpy(y_train.to_numpy().astype(np.float32))\n",
    "    y_test=torch.from_numpy(y_test.to_numpy().astype(np.float32))\n",
    "\n",
    "    y_train=y_train.view(y_train.shape[0],1)\n",
    "    y_test=y_test.view(y_test.shape[0],1)\n",
    "\n",
    "    traindata = MyDataset(x_train, y_train)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(traindata, batch_size=1000, shuffle=True)\n",
    "\n",
    "    n_features = x_train.shape[1]\n",
    "    model=Logistic_Reg_model(n_features)\n",
    "\n",
    "    criterion=torch.nn.BCELoss(reduction='none')\n",
    "    robust_loss = RobustLoss(geometry='chi-square', size=1.0, reg=0.5)\n",
    "    optimizer=torch.optim.Adam(model.parameters())#,lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "    number_of_epochs=100\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(number_of_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (x_b, y_b) in enumerate(trainloader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            y_prediction=model(x_b)\n",
    "            loss=robust_loss(criterion(y_prediction.squeeze(),y_b.squeeze()))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() \n",
    "            if (i)%10 == 9:\n",
    "                print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 10))\n",
    "                running_loss = 0.0\n",
    "        accuracy = testaccuracy()\n",
    "        print('accuracy:', accuracy)\n",
    "        print('best:', best_accuracy)\n",
    "        if accuracy > best_accuracy:\n",
    "            saveModel()\n",
    "            best_accuracy = accuracy\n",
    "\n",
    "    finalmodel = Logistic_Reg_model(n_features)\n",
    "    finalmodel.load_state_dict(torch.load('DRO_model.pth'))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred=finalmodel(x_test)\n",
    "        y_pred_class=y_pred.round()\n",
    "        try:\n",
    "            os.mkdir(path+'preds/')\n",
    "        except:\n",
    "            pass\n",
    "        torch.save(y_pred_class,path+'preds/OG_DRO_pred.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
