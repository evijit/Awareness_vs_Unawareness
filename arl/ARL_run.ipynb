{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reimplementing the Adversarially Reweighted Learning model by Lahoti et al. (2020) to improve fairness without demographics\n",
    "\n",
    "\n",
    "\n",
    "This notebook contains the results presented in the paper by J. Mohazzab, L. Weytingh, C. Wortmann, and B. Brocades Zaalberg. More specifically, it contains the presented results for replicating [the paper by Lahoti et al.](https://arxiv.org/abs/2006.13114). In addition, this notebook includes the significance tests presented in Section 3.4.1 of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import train\n",
    "from argparser import DefaultArguments, get_optimal_parameters\n",
    "from significance import test_significance\n",
    "from glob import glob\n",
    "import os\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Parameters\n",
    "\n",
    "The default parameters are loaded below. They can be changed, e.g. for speeding up the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The default parameters are:\n",
      " {'average_over': 10, 'dataset': 'compas', 'train_steps': 1000, 'pretrain_steps': 250, 'batch_size': 32, 'optimizer': 'Adagrad', 'embedding_size': 32, 'lr_learner': 0.01, 'lr_adversary': 0.01, 'test_every': 5, 'seed': 42, 'log_dir': 'logs/', 'res_dir': 'results/', 'print_loss': False, 'model_name': 'ARL'}\n"
     ]
    }
   ],
   "source": [
    "# Load the default arguments\n",
    "default_args = DefaultArguments()\n",
    "\n",
    "# Change if the loss should be printed\n",
    "default_args.print_loss = False\n",
    "\n",
    "# Change the amount of times the results are averaged here.\n",
    "default_args.average_over = 10\n",
    "\n",
    "# Change the amount of training steps for each of the datasets here.\n",
    "training_steps = {\n",
    "    \"uci_adult\": 990,\n",
    "    \"law_school\": 990,\n",
    "    \"compas\": 470,\n",
    "}\n",
    "\n",
    "print(\"The default parameters are:\\n\", default_args.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicability\n",
    "\n",
    "The presented results for the PyTorch implementation are generated below for each classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '../data/datasets/uci_adult/'\n",
    "# synthfols = glob(\"../data/datasets/uci_adult/synthetic/*/\")\n",
    "# paths = [path]\n",
    "# paths.extend(synthfols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Load the optimal hyperparameters.\n",
    "# for path in paths:\n",
    "#     if True:#os.path.exists(path+'preds/ARL_pred.pt') == False:\n",
    "#         try:\n",
    "#             print(path)\n",
    "#             adult_params = get_optimal_parameters(\"uci_adult\")\n",
    "#             adult_params[\"train_steps\"] = training_steps[\"uci_adult\"]\n",
    "\n",
    "#             # Load the arguments passed to the training function.\n",
    "#             adult_args = copy.copy(default_args)\n",
    "#             adult_args.dataset = path\n",
    "#             adult_args.update(adult_params)\n",
    "\n",
    "#             print(\"Parameters used for the Adult dataset:\\n\", adult_params)\n",
    "\n",
    "#             # Start timing.\n",
    "#             adult_start = time.time()\n",
    "\n",
    "#             # Train the model.\n",
    "#             train.main(adult_args)\n",
    "\n",
    "#             # Save the timing results.\n",
    "#             adult_time = (time.time() - adult_start) / adult_args.average_over\n",
    "#             print(f\"Training and evaluating took, on average, {adult_time:.0f} seconds per model iteration for Adult\")\n",
    "#         except:\n",
    "#             traceback.print_exc()\n",
    "#             print ('error for this run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths  = ['../data/datasets/publiccov_ca/', '../data/datasets/employment_ca/', '../data/datasets/law_school/', '../data/datasets/diabetes/']\n",
    "\n",
    "# path = '../data/datasets/law_school/'\n",
    "# synthfols = glob(\"../data/datasets/law_school/synthetic/*/\")\n",
    "# paths.append(path)\n",
    "# paths.extend(synthfols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/datasets/publiccov_ca/ 0\n",
      "Parameters used for the Adult dataset:\n",
      " {'batch_size': 256, 'lr_learner': 0.01, 'lr_adversary': 1, 'train_steps': 990}\n",
      "Training model 1/10\n",
      "Training model 2/10\n",
      "Training model 3/10\n",
      "Training model 10/10\n",
      "Training model 3/10\n",
      "Training model 4/10\n",
      "Training model 5/10\n",
      "Training model 6/10\n",
      "Training model 7/10\n",
      "Training model 3/10\n",
      "Training model 8/10\n",
      "Training model 9/10\n",
      "Training model 10/10\n",
      "Done training\n",
      "\n",
      "-----------------------------------\n",
      "Results\n",
      "\n",
      "Average AUC: 0.725 ± 0.0031\n",
      "Average AUC(macro-avg): 0.725\n",
      "Average AUC(min): 0.720\n",
      "Average AUC(minority): 0.720\n",
      "-----------------------------------\n",
      "\n",
      "Training and evaluating took, on average, 178 seconds per model iteration for Adult\n",
      "../data/datasets/employment_ca/ 0\n",
      "Parameters used for the Adult dataset:\n",
      " {'batch_size': 256, 'lr_learner': 0.01, 'lr_adversary': 1, 'train_steps': 990}\n",
      "Training model 1/10\n",
      "Training model 2/10\n",
      "Training model 4/10\n",
      "Training model 5/10\n",
      "Training model 6/10\n",
      "Training model 7/10\n",
      "Training model 8/10\n",
      "Training model 2/10\n",
      "Training model 9/10\n",
      "Training model 10/10\n",
      "Done training\n",
      "\n",
      "-----------------------------------\n",
      "Results\n",
      "\n",
      "Average AUC: 0.883 ± 0.0014\n",
      "Average AUC(macro-avg): 0.885\n",
      "Average AUC(min): 0.860\n",
      "Average AUC(minority): 0.909\n",
      "-----------------------------------\n",
      "\n",
      "Training and evaluating took, on average, 161 seconds per model iteration for Adult\n",
      "../data/datasets/employment_ca/ 5\n",
      "Parameters used for the Adult dataset:\n",
      " {'batch_size': 256, 'lr_learner': 0.01, 'lr_adversary': 1, 'train_steps': 990}\n",
      "Training model 1/10\n",
      "Training model 2/10\n",
      "Training model 3/10\n",
      "Training model 4/10\n",
      "Training model 3/10\n",
      "Training model 5/10\n",
      "Training model 6/10\n",
      "Training model 7/10\n",
      "Training model 8/10\n",
      "Training model 9/10\n",
      "Training model 10/10\n",
      "Done training\n",
      "\n",
      "-----------------------------------\n",
      "Results\n",
      "\n",
      "Average AUC: 0.791 ± 0.0063\n",
      "Average AUC(macro-avg): 0.791\n",
      "Average AUC(min): 0.787\n",
      "Average AUC(minority): 0.796\n",
      "-----------------------------------\n",
      "\n",
      "Training and evaluating took, on average, 89 seconds per model iteration for Adult\n",
      "../data/datasets/law_school/ 4\n",
      "Parameters used for the Adult dataset:\n",
      " {'batch_size': 256, 'lr_learner': 0.01, 'lr_adversary': 1, 'train_steps': 990}\n",
      "Training model 1/10\n",
      "Training model 2/10\n",
      "Training model 3/10\n",
      "Training model 4/10\n",
      "Training model 5/10\n",
      "Training model 6/10\n",
      "Training model 8/10\n",
      "Training model 4/10\n",
      "Training model 10/10\n",
      "Done training\n",
      "\n",
      "-----------------------------------\n",
      "Results\n",
      "\n",
      "Average AUC: 0.658 ± 0.0021\n",
      "Average AUC(macro-avg): 0.659\n",
      "Average AUC(min): 0.653\n",
      "Average AUC(minority): 0.664\n",
      "-----------------------------------\n",
      "\n",
      "Training and evaluating took, on average, 181 seconds per model iteration for Adult\n",
      "../data/datasets/diabetes/ 1\n",
      "Parameters used for the Adult dataset:\n",
      " {'batch_size': 256, 'lr_learner': 0.01, 'lr_adversary': 1, 'train_steps': 990}\n",
      "Training model 1/10\n",
      "Training model 2/10\n",
      "Training model 3/10\n",
      "Training model 4/10\n",
      "Training model 10/10\n",
      "Done training\n",
      "\n",
      "-----------------------------------\n",
      "Results\n",
      "\n",
      "Average AUC: 0.658 ± 0.0025\n",
      "Average AUC(macro-avg): 0.658\n",
      "Average AUC(min): 0.653\n",
      "Average AUC(minority): 0.664\n",
      "-----------------------------------\n",
      "\n",
      "Training and evaluating took, on average, 181 seconds per model iteration for Adult\n",
      "../data/datasets/diabetes/ 2\n",
      "Parameters used for the Adult dataset:\n",
      " {'batch_size': 256, 'lr_learner': 0.01, 'lr_adversary': 1, 'train_steps': 990}\n",
      "Training model 1/10\n",
      "Training model 2/10\n",
      "Training model 3/10\n",
      "Training model 4/10\n",
      "Training model 5/10\n",
      "Training model 5/10\n",
      "Training model 4/10\n"
     ]
    }
   ],
   "source": [
    "# Load the optimal hyperparameters.\n",
    "for path in paths:\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            print(path,i)\n",
    "            adult_params = get_optimal_parameters(\"uci_adult\")\n",
    "            adult_params[\"train_steps\"] = training_steps[\"uci_adult\"]\n",
    "\n",
    "            # Load the arguments passed to the training function.\n",
    "            adult_args = copy.copy(default_args)\n",
    "            adult_args.dataset = path\n",
    "            adult_args.update(adult_params)\n",
    "\n",
    "            print(\"Parameters used for the Adult dataset:\\n\", adult_params)\n",
    "\n",
    "            # Start timing.\n",
    "            adult_start = time.time()\n",
    "\n",
    "            # Train the model.\n",
    "            train.main(adult_args)\n",
    "\n",
    "            # Save the timing results.\n",
    "            adult_time = (time.time() - adult_start) / adult_args.average_over\n",
    "            print(f\"Training and evaluating took, on average, {adult_time:.0f} seconds per model iteration for Adult\")\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            print ('error for this run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:arl_uva]",
   "language": "python",
   "name": "conda-env-arl_uva-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
