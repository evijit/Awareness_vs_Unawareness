{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from aif360.sklearn.preprocessing import Reweighing, ReweighingMeta, FairAdapt, LearnedFairRepresentations\n",
    "from aif360.sklearn.inprocessing import AdversarialDebiasing, ExponentiatedGradientReduction, GridSearchReduction\n",
    "from aif360.sklearn.postprocessing import CalibratedEqualizedOdds, RejectOptionClassifier, PostProcessingMeta, RejectOptionClassifierCV\n",
    "from aif360.sklearn.datasets import fetch_adult\n",
    "from aif360.sklearn.metrics import disparate_impact_ratio, average_odds_error, generalized_fpr\n",
    "from aif360.sklearn.metrics import generalized_fnr, difference\n",
    "\n",
    "# from glob import glob\n",
    "# import json,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,os\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "def writejson(path,arr,name):\n",
    "    try:\n",
    "        os.mkdir(path+'preds/')\n",
    "    except:\n",
    "        pass\n",
    "    f = open(path+'preds/'+name,'w')\n",
    "    json.dump(arr.tolist(),f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/datasets/uci_adult/'\n",
    "synthfols = glob(\"data/datasets/uci_adult/synthetic/*_version0/\")\n",
    "paths = [path]\n",
    "paths.extend(synthfols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(path):\n",
    "    \n",
    "#     if os.path.exists(path+'preds/baseline_pred.json') == False:\n",
    "\n",
    "#     train_df = pd.read_csv(path+'train.csv',header=None)\n",
    "\n",
    "#     train_df.columns = ['age', 'workclass', 'fnlwgt','education', 'education-num', 'marital-status',\n",
    "#            'occupation', 'relationship', 'race', 'sex', 'capital-gain',\n",
    "#            'capital-loss', 'hours-per-week', 'native-country','income']\n",
    "\n",
    "#     train_df.index = train_df['sex']\n",
    "\n",
    "#     train_df = train_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "#     test_df = pd.read_csv(path+'test.csv',header=None)\n",
    "\n",
    "#     test_df.columns = ['age', 'workclass', 'fnlwgt','education', 'education-num', 'marital-status',\n",
    "#            'occupation', 'relationship', 'race', 'sex', 'capital-gain',\n",
    "#            'capital-loss', 'hours-per-week', 'native-country','income']\n",
    "\n",
    "#     test_df.index = test_df['sex']\n",
    "\n",
    "#     test_df = test_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "\n",
    "#     X_train = train_df.drop(['income'],axis=1)\n",
    "#     X_test = test_df.drop(['income'],axis=1)\n",
    "\n",
    "#     y_train = pd.Series(train_df['income'])\n",
    "#     y_test = pd.Series(test_df['income'])\n",
    "\n",
    "#     y_train = pd.Series(y_train.factorize(sort=True)[0], index=y_train.index)\n",
    "#     y_test = pd.Series(y_test.factorize(sort=True)[0], index=y_test.index)\n",
    "\n",
    "#     X_merged = pd.concat([X_train,X_test])\n",
    "\n",
    "#     ohe = make_column_transformer(\n",
    "#         (OneHotEncoder(sparse=False), X_merged.dtypes == 'object'),\n",
    "#         remainder='passthrough', verbose_feature_names_out=False)\n",
    "\n",
    "#     X_merged_temp  = pd.DataFrame(ohe.fit_transform(X_merged), columns=ohe.get_feature_names_out(), index=X_merged.index)\n",
    "\n",
    "#     X_train  = pd.DataFrame(ohe.transform(X_train), columns=ohe.get_feature_names_out(), index=X_train.index)\n",
    "#     X_test = pd.DataFrame(ohe.transform(X_test), columns=ohe.get_feature_names_out(), index=X_test.index)\n",
    "\n",
    "\n",
    "#     #### BASELINE\n",
    "#     y_pred_baseline = LogisticRegression(solver='liblinear').fit(X_train, y_train).predict(X_test)\n",
    "#     writejson(path,y_pred_baseline,'baseline_pred.json')\n",
    "\n",
    "#     #### Adv. Reweighting (Preproc.)\n",
    "\n",
    "#     rew = ReweighingMeta(estimator=LogisticRegression(solver='liblinear'),\n",
    "#                      reweigher=Reweighing('sex'))\n",
    "\n",
    "#     params = {'estimator__C': [1, 10]}\n",
    "\n",
    "#     clf = GridSearchCV(rew, params, scoring='accuracy', cv=5)\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     y_pred_advrew = clf.predict(X_test)\n",
    "#     writejson(path,y_pred_advrew,'adv_rew_pred.json')\n",
    "\n",
    "#     #### LearnedFairRepresentations (Preproc.)\n",
    "\n",
    "#     LFR = LearnedFairRepresentations(prot_attr='sex')\n",
    "#     LFR.fit(X_train, y_train)\n",
    "\n",
    "#     y_pred_lfr = LFR.predict(X_test)\n",
    "#     writejson(path,y_pred_lfr,'lfr_pred.json')\n",
    "\n",
    "#     #### Adv Deb. (Inproc.)\n",
    "\n",
    "#     adv_deb = AdversarialDebiasing(prot_attr='sex')\n",
    "#     adv_deb.fit(X_train, y_train)\n",
    "#     adv_deb.score(X_test, y_test)\n",
    "\n",
    "#     y_pred_adv_deb = adv_deb.predict(X_test)\n",
    "#     writejson(path,y_pred_adv_deb,'adv_deb_pred.json')\n",
    "\n",
    "#     adv_deb.sess_.close()\n",
    "\n",
    "#     #### ExponentiatedGradientReduction. (Inproc.)\n",
    "\n",
    "#     consts = ['ErrorRateParity']#['DemographicParity','EqualizedOdds','TruePositiveRateParity','FalsePositiveRateParity','ErrorRateParity']\n",
    "#     for const in consts:\n",
    "#         EGR = ExponentiatedGradientReduction(prot_attr=['sex_Female','sex_Male'], estimator=LogisticRegression(solver='liblinear'), constraints = const)\n",
    "#         EGR.fit(X_train, y_train)\n",
    "#         print(const,EGR.score(X_test, y_test))\n",
    "#         y_pred_egr = EGR.predict(X_test)\n",
    "#         writejson(path,y_pred_egr,'egr_pred_'+const+'.json')\n",
    "\n",
    "#     #### GridSearchReduction. (Inproc.)\n",
    "\n",
    "#     consts = ['ErrorRateParity']#['DemographicParity','EqualizedOdds','TruePositiveRateParity','FalsePositiveRateParity','ErrorRateParity']\n",
    "#     for const in consts:\n",
    "#         GSR = GridSearchReduction(prot_attr=['sex_Female','sex_Male'], estimator=LogisticRegression(solver='liblinear'), constraints = const)\n",
    "#         GSR.fit(X_train, y_train)\n",
    "#         print(const,GSR.score(X_test, y_test))\n",
    "#         y_pred_gsr = GSR.predict(X_test)\n",
    "#         writejson(path,y_pred_gsr,'gsr_pred_'+const+'.json')\n",
    "\n",
    "\n",
    "\n",
    "#     X_train_temp = X_train.set_index(['sex_Male'], drop = False)\n",
    "#     y_train_temp = y_train.copy()\n",
    "#     y_train_temp.index = X_train_temp.index\n",
    "\n",
    "#     X_test_temp = X_test.set_index(['sex_Male'], drop = False)\n",
    "#     y_test_temp = y_test.copy()\n",
    "#     y_test_temp.index = X_test_temp.index\n",
    "\n",
    "#     #### Cal. Eq.Odds (Postproc.)\n",
    "\n",
    "#     consts = ['weighted']#['fnr','fpr','weighted']\n",
    "#     for const in consts:\n",
    "#         cal_eq_odds = CalibratedEqualizedOdds(prot_attr='sex_Male', cost_constraint=const)\n",
    "#         postproc = PostProcessingMeta(estimator=LogisticRegression(solver='liblinear'), postprocessor=cal_eq_odds)\n",
    "#         postproc.fit(X_train_temp, y_train_temp)\n",
    "#         print(accuracy_score(y_test_temp, postproc.predict(X_test_temp)))\n",
    "#         y_pred_caleq = postproc.predict(X_test_temp)\n",
    "#         writejson(path,y_pred_caleq,'caleq_pred_'+const+'.json')\n",
    "\n",
    "#     #### RejectOptionClassifier (Postproc.)\n",
    "\n",
    "#     consts = ['average_odds']#['statistical_parity', 'average_odds', 'equal_opportunity']\n",
    "#     for const in consts:\n",
    "#         rocv = PostProcessingMeta(LogisticRegression(solver='liblinear'), RejectOptionClassifierCV('sex_Male', scoring=const))\n",
    "#         rocv.fit(X_train_temp, y_train_temp)\n",
    "#         print(accuracy_score(y_test_temp, rocv.predict(X_test_temp)))\n",
    "#         y_pred_rocv = rocv.predict(X_test_temp)\n",
    "#         writejson(path,y_pred_rocv,'rocv_pred_'+const+'.json')\n",
    "        \n",
    "    os.system('python3 fair-classification-with-noisy-labels/run.py --path '+path)\n",
    "    \n",
    "    return path,\"Done\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task(paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data/datasets/uci_adult/synthetic/income_flip_labels0.4_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_groupsize0.4_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_groupsize0.2_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/income_flip_labels0.2_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/income_flip_labels0.5_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/income_flip_labels0.3_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_groupsize0.3_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/income_flip_labels0.1_version0/', 'Done')\n",
      "('data/datasets/uci_adult/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_groupsize0.1_version0/', 'Done')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "Traceback (most recent call last):\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "Traceback (most recent call last):\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "Traceback (most recent call last):\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data/datasets/uci_adult/synthetic/female_groupsize0.5_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_groupsize0.8_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_baserate0.3_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_baserate0.2_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_baserate0.4_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_baserate0.5_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_groupsize0.6_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_groupsize0.9_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_groupsize0.7_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_baserate0.1_version0/', 'Done')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/avijit/projects/Awareness_vs_Unawareness/fair-classification-with-noisy-labels/run.py\", line 15, in <module>\n",
      "    from cleanlab.classification import LearningWithNoisyLabels\n",
      "ImportError: cannot import name 'LearningWithNoisyLabels' from 'cleanlab.classification' (/home/avijit/anaconda3/envs/pablo/lib/python3.10/site-packages/cleanlab/classification.py)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data/datasets/uci_adult/synthetic/female_baserate0.8_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_baserate0.7_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_baserate0.9_version0/', 'Done')\n",
      "('data/datasets/uci_adult/synthetic/female_baserate0.6_version0/', 'Done')\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "\n",
    "pool = Pool(10)\n",
    "for result in pool.imap_unordered(task, paths):\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FairAdapt (Preproc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XY_df = pd.concat([X_train, y_train], axis=1)\n",
    "# adj_mat = pd.DataFrame(\n",
    "#     np.zeros((len(train_df.columns), len(train_df.columns)), dtype=int),\n",
    "#     index=train_df.columns.values,\n",
    "#     columns=train_df.columns.values\n",
    "# )\n",
    "\n",
    "# # Construct the adjacency matrix of the causal graph\n",
    "# adj_mat.at[\n",
    "#     [\"sex\", \"age\", \"native-country\"],\n",
    "#     [\"marital-status\", \"education-num\", \"workclass\", \"hours-per-week\",\n",
    "#      \"occupation\", \"annual-income\"]\n",
    "# ] = 1\n",
    "# adj_mat.at[\n",
    "#     \"marital-status\",\n",
    "#     [\"education-num\", \"workclass\", \"hours-per-week\", \"occupation\",\n",
    "#      \"annual-income\"]\n",
    "# ] = 1\n",
    "# adj_mat.at[\n",
    "#     \"education-num\",\n",
    "#     [\"workclass\", \"hours-per-week\", \"occupation\", \"annual-income\"]\n",
    "# ] = 1\n",
    "# adj_mat.at[\n",
    "#     [\"workclass\", \"hours-per-week\", \"occupation\"],\n",
    "#     \"annual-income\"\n",
    "# ] = 1\n",
    "\n",
    "# FA = FairAdapt(prot_attr='sex', adj_mat = adj_mat)\n",
    "\n",
    "\n",
    "# Xf_train, yf_train, Xf_test = FA.fit_transform(X_train, y_train, X_test)\n",
    "# # y_pred_advrew = clf.predict(X_test)\n",
    "# # writejson(y_pred_advrew,'adv_rew_pred.json')\n",
    "\n",
    "\n",
    "#### TAKING TOO LONG TO PROCESS #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'education-num',\n",
       " 'fnlwgt',\n",
       " 'hours-per-week'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X_train.columns).intersection(set(X_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['workclass_?', 'workclass_Federal-gov', 'workclass_Local-gov',\n",
       "       'workclass_Never-worked', 'workclass_Private', 'workclass_Self-emp-inc',\n",
       "       'workclass_Self-emp-not-inc', 'workclass_State-gov',\n",
       "       'workclass_Without-pay', 'education_10th',\n",
       "       ...\n",
       "       'native-country_Trinadad&Tobago', 'native-country_United-States',\n",
       "       'native-country_Vietnam', 'native-country_Yugoslavia', 'age', 'fnlwgt',\n",
       "       'education-num', 'capital-gain', 'capital-loss', 'hours-per-week'],\n",
       "      dtype='object', length=107)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('still runnung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:arl_uva]",
   "language": "python",
   "name": "conda-env-arl_uva-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
